{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8514,
     "status": "ok",
     "timestamp": 1731905091784,
     "user": {
      "displayName": "Mangalavinayagam Umashankar",
      "userId": "10664991290733820132"
     },
     "user_tz": -330
    },
    "id": "qt8M-g8dlfco",
    "outputId": "8161f405-1173-461b-abce-abcb1a22c37b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchaudio numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fC7RX5O7lxnq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from torchaudio.models import Tacotron2\n",
    "from torch import quantization\n",
    "from IPython.display import Audio\n",
    "import torchaudio.functional as F\n",
    "\n",
    "\n",
    "model = torchaudio.models.Tacotron2.from_pretrained(\"tacotron2\")\n",
    "model.eval()\n",
    "\n",
    "model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "\n",
    "model_prepared = torch.quantization.prepare(model)\n",
    "\n",
    "model_quantized = torch.quantization.convert(model_prepared)\n",
    "\n",
    "print(\"Model successfully quantized.\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    A simple function to preprocess input text.\n",
    "    - Converts the text to lowercase.\n",
    "    - Other text normalization can be added.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "input_text = \"Hello, this is a Text-to-Speech system using quantized models.\"\n",
    "processed_text = preprocess_text(input_text)\n",
    "\n",
    "def text_to_speech(model, text):\n",
    "    \"\"\"\n",
    "    Convert input text to speech.\n",
    "    - Convert text to a tensor of input IDs (simulated here as ASCII values).\n",
    "    - Generate the spectrogram.\n",
    "    \"\"\"\n",
    "    input_ids = torch.tensor([ord(char) for char in text], dtype=torch.int32).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        spectrogram, _, _ = model(input_ids)\n",
    "\n",
    "    return spectrogram\n",
    "\n",
    "spectrogram = text_to_speech(model_quantized, processed_text)\n",
    "\n",
    "def spectrogram_to_waveform(spectrogram):\n",
    "    \"\"\"\n",
    "    Convert the spectrogram to waveform using Griffin-Lim vocoder.\n",
    "    This is a simplified vocoder for demonstration purposes.\n",
    "    \"\"\"\n",
    "    waveform = F.griffinlim(spectrogram)\n",
    "    return waveform\n",
    "\n",
    "waveform = spectrogram_to_waveform(spectrogram)\n",
    "import torchaudio\n",
    "\n",
    "torchaudio.save(\"output.wav\", waveform, sample_rate=22050)\n",
    "\n",
    "print(\"Audio saved as 'output.wav'.\")\n",
    "\n",
    "Audio(\"output.wav\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOIF5vO40P6vI0R3EOzjApl",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
